{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824b842-9cf8-40fb-9792-ec3b17167001",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_PATH       = \"../data/processed/2_cleaned_data.pkl\"\n",
    "\n",
    "ROLE_COLS      = ['DevType']\n",
    "TECH_COLS      = ['LanguageWorkedWith',    'DatabaseWorkedWith',    'WebframeWorkedWith',    'MiscTechWorkedWith']\n",
    "\n",
    "EXPERIMENT_NAME = \"stackoverflow_single_model\"\n",
    "LOG_PATH = \"../models/temp/random_forest/\"\n",
    "LOG_DATA_PKL    =  \"data.pkl\"\n",
    "LOG_MODEL_PKL   =  \"model.pkl\"\n",
    "LOG_METRICS_PKL =  \"metrics.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c1608-0388-4846-bef3-d6cb67ed7539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "import random\n",
    "import plotly \n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3f245-5fe8-4f1a-a135-a9a670419bc5",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a3f45d-ebb9-43a9-a8a6-51784614b8ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6b35c-9776-4b34-b994-c00aa88c2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data \n",
    "df = pd.read_pickle(DF_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717dc150-ba0c-48a2-9cfc-a6d259cff5c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91508beb-46d3-416f-a359-cbd9f234afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(ground_truth, prediction, metric_function, sort_values=False):\n",
    "    quality_scores = {}\n",
    "    for col in predictions.columns:\n",
    "        role_pred  = predictions[col].copy()\n",
    "        role_truth = ground_truth[col].copy()\n",
    "        quality_scores[col] = round(metric_function(role_truth, role_pred) * 100, 2)\n",
    "        \n",
    "    quality_scores = pd.Series(quality_scores.values(), index=quality_scores.keys())\n",
    "    if sort_values:\n",
    "        quality_scores = quality_scores.sort_values()\n",
    "    \n",
    "    return quality_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d7a9c-3b9e-44bf-a360-28879aca6720",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Balance classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4498b3-c98d-43a2-89d6-9f957c3163c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the total samples of roles\n",
    "roles_df = df[\"DevType\"].copy()\n",
    "role_sum = df[\"DevType\"].sum(axis=0)\n",
    "role_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca9b69a-cd32-446e-a72c-31d67fb7b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample roles\n",
    "samples_per_class = 500\n",
    "resampled_roles = []\n",
    "\n",
    "for role_col in roles_df.columns:\n",
    "    sub_df = roles_df.loc[roles_df[role_col] == 1].copy()\n",
    "    \n",
    "    if len(sub_df) < samples_per_class:\n",
    "        # Upsample\n",
    "        sub_df = sub_df.sample(samples_per_class, replace=True, random_state=0)\n",
    "    else:\n",
    "        # Downsample\n",
    "        sub_df = sub_df.sample(samples_per_class, random_state=0) \n",
    "    \n",
    "    resampled_roles.append(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243ca57-c4c6-4e07-b7ee-e8e4ad5052a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dfs\n",
    "roles_df  = pd.concat(resampled_roles)\n",
    "df = df.loc[roles_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f6e9d-8322-451b-9f13-cdc3281c0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles_df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5833db-2a42-4ee4-bc1b-343a45235f7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17cc20-d76b-4d30-84c1-62aad2ad3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop(\"DevType\", axis=1), \n",
    "                                                    df[\"DevType\"], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad322cb-3220-4a91-bd04-de8e3f05b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef0d4b-1f3c-4f01-9533-fe24b82f3ef1",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f31fd6c-f625-4d5d-851c-8e6fed42bfe5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2db7a05-fbdf-404c-af01-d50cd3adba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client and experiment\n",
    "client = MlflowClient()\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "exp = client.get_experiment_by_name(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd1430-e867-4e22-91b6-2dd874cfedcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Vanilla Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c6b62-f601-4196-b099-2229d5da913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = make_pipeline(StandardScaler(),\n",
    "                       RandomForestClassifier(random_state=0))\n",
    "\n",
    "rf_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97beec7e-8bce-4453-b0d5-044ef51b1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on train set\n",
    "predictions =  pd.DataFrame(rf_clf.predict(X_train), columns=Y_train.columns)\n",
    "train_scores = {score.__name__: calculate_quality(Y_train, predictions, score) \n",
    "                for score in [accuracy_score, precision_score, recall_score, f1_score]}\n",
    "train_scores = pd.concat(train_scores,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a02d9-11c7-488c-8094-970d0cdf06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "predictions =  pd.DataFrame(rf_clf.predict(X_test), columns=Y_test.columns)\n",
    "test_scores = {score.__name__: calculate_quality(Y_test, predictions, score) \n",
    "                for score in [accuracy_score, precision_score, recall_score, f1_score]}\n",
    "test_scores = pd.concat(test_scores,axis=1)\n",
    "mean_test_scores = test_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fafcee-428e-4b22-91df-594243970974",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_scores.mean())\n",
    "test_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d462039-39ae-4f61-b779-dce749dbd21b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dff34e-8fbe-4704-a43e-a7c7ca6bc8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data details\n",
    "data_details = {\"data_path\": DF_PATH,\n",
    "                \"training_indices\": X_train.index.tolist(),\n",
    "                \"test_indices\":     X_test.index.tolist(), \n",
    "                \"features_names\":   X_train.columns.droplevel(0).tolist(),\n",
    "                \"targets_names\":    Y_train.columns.tolist()}\n",
    "\n",
    "with open(os.path.join(LOG_PATH, LOG_DATA_PKL), \"wb\") as output_file:\n",
    "    pickle.dump(data_details, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e2a97-5b40-45c5-8910-4557281bc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = {\"model_description\": \"Random Forest: with non linearity\",\n",
    "         \"model_details\": str(rf_clf),\n",
    "         \"model_object\": rf_clf} \n",
    "\n",
    "with open(os.path.join(LOG_PATH, LOG_MODEL_PKL), \"wb\") as output_file:\n",
    "    pickle.dump(model, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed1a46-1b30-4e00-ac8e-a2017716244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preformance details\n",
    "classes_metrics = {\"train_scores\": train_scores, \n",
    "                   \"test_scores\":  test_scores}\n",
    "\n",
    "with open(os.path.join(LOG_PATH, LOG_METRICS_PKL), \"wb\") as output_file:\n",
    "    pickle.dump(classes_metrics, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a80f2-8162-46fc-9f63-4086dec7919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new run and track \n",
    "with mlflow.start_run(experiment_id=exp.experiment_id, \n",
    "                      run_name=model[\"model_description\"]):\n",
    "    # Log pickles\n",
    "    mlflow.log_artifacts(LOG_PATH)  \n",
    "    \n",
    "    # Track metrics \n",
    "    for metric, score in mean_test_scores.items():\n",
    "        mlflow.log_metric(metric, score) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef39c040-6ac4-4d27-aa66-61128dc20dba",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27591dd-e7fb-4926-a062-7721bffb71b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Random Forest with Non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea5966-b97d-439f-b625-ab17705b3237",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = make_pipeline(StandardScaler(), \n",
    "                       FeatureUnion([('linear_pca', PCA(n_components=40)), \n",
    "                                      ('kernel_pca', KernelPCA(n_components=40, \n",
    "                                                               kernel='rbf'))]),\n",
    "                       RandomForestClassifier(random_state=0))\n",
    "\n",
    "rf_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61f3ac-6197-4b25-98fd-a19a6453dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on train set\n",
    "predictions =  pd.DataFrame(rf_clf.predict(X_train), columns=Y_train.columns)\n",
    "train_scores = {score.__name__: calculate_quality(Y_train, predictions, score) \n",
    "                for score in [accuracy_score, precision_score, recall_score, f1_score]}\n",
    "train_scores = pd.concat(train_scores,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f042c4-e1f2-4285-97c1-0d5723631b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "predictions =  pd.DataFrame(rf_clf.predict(X_test), columns=Y_test.columns)\n",
    "test_scores = {score.__name__: calculate_quality(Y_test, predictions, score) \n",
    "                for score in [accuracy_score, precision_score, recall_score, f1_score]}\n",
    "test_scores = pd.concat(test_scores,axis=1)\n",
    "mean_test_scores = test_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014158b-3f48-4e3f-9eff-ce2cd00a1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_test_scores)\n",
    "test_scores.sort_values(\"f1_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25233336-c676-4003-aa2f-6ffe4d6638ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6963d8a-dc50-4996-8d99-cd2c90bf9f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data details\n",
    "data_details = {\"data_path\": DF_PATH,\n",
    "                \"training_indices\": X_train.index.tolist(),\n",
    "                \"test_indices\":     X_test.index.tolist(), \n",
    "                \"features_names\":   X_train.columns.droplevel(0).tolist(),\n",
    "                \"targets_names\":    Y_train.columns.tolist()}\n",
    "\n",
    "with open(os.path.join(LOG_PATH, LOG_DATA_PKL), \"wb\") as output_file:\n",
    "    pickle.dump(data_details, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff35c33-613d-48db-8916-de2a0dabde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = {\"model_description\": \"Random Forest: with PCAs + RBF kernel\",\n",
    "         \"model_details\": str(rf_clf),\n",
    "         \"model_object\": rf_clf} \n",
    "\n",
    "with open(os.path.join(LOG_PATH, LOG_MODEL_PKL), \"wb\") as output_file:\n",
    "    pickle.dump(model, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95faf6a6-e46c-459d-ace8-c3352eadd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preformance details\n",
    "classes_metrics = {\"train_scores\": train_scores, \n",
    "                   \"test_scores\":  test_scores}\n",
    "\n",
    "with open(os.path.join(LOG_PATH, LOG_METRICS_PKL), \"wb\") as output_file:\n",
    "    pickle.dump(classes_metrics, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acd88f-04bc-4922-a1b0-1db7a431f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new run and track \n",
    "with mlflow.start_run(experiment_id=exp.experiment_id, \n",
    "                      run_name=model[\"model_description\"]):\n",
    "    # Log pickles\n",
    "    mlflow.log_artifacts(LOG_PATH)  \n",
    "    \n",
    "    # Track metrics \n",
    "    for metric, score in mean_test_scores.items():\n",
    "        mlflow.log_metric(metric, score) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446d231-f545-4188-89c8-0bb6dcb7953e",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88534cac-cf76-4498-8576-c9b061d474a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Random Forest with PCAs & Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4ce18-8c30-4628-8267-6675d812a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpt_rf_clf = make_pipeline(StandardScaler(), \n",
    "                           FeatureUnion([('linear_pca', PCA()), \n",
    "                                         ('kernel_pca', KernelPCA(kernel='rbf'))]),\n",
    "                           RandomForestClassifier(random_state=0, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0aa9be-727d-4deb-9712-5a856df1ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(hpt_rf_clf.get_params().keys())\n",
    "tuned_parameters = [{'featureunion__linear_pca__n_components': [5, 10, 20, 40, 60], \n",
    "                     'featureunion__kernel_pca__n_components': [5, 10, 20, 40, 60],\n",
    "                     'randomforestclassifier__n_estimators':   [100, 500, 1000]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2df48b-343a-438f-90d5-3c40bec79685",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpt_rf_clf = GridSearchCV(hpt_rf_clf, \n",
    "                          tuned_parameters, \n",
    "                          n_jobs=-1)\n",
    "\n",
    "hpt_rf_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3666b9b-a4d7-406d-bc2d-71e5f68fd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpt_rf_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d05d4-c404-4011-b28c-16a1abd22af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "predictions =  pd.DataFrame(hpt_rf_clf.predict(X_train), columns=Y_train.columns)\n",
    "train_scores = {score.__name__: calculate_quality(Y_train, predictions, score) \n",
    "                for score in [accuracy_score, precision_score, recall_score, f1_score]}\n",
    "train_scores = pd.concat(train_scores,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4154f0-7ec6-43f9-8405-f1398704d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "predictions =  pd.DataFrame(hpt_rf_clf.predict(X_test), columns=Y_test.columns)\n",
    "test_scores = {score.__name__: calculate_quality(Y_test, predictions, score) \n",
    "                for score in [accuracy_score, precision_score, recall_score, f1_score]}\n",
    "test_scores = pd.concat(test_scores,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaaa74d-834d-4794-a906-34032288dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_scores.mean())\n",
    "test_scores.sort_values(\"f1_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863e7cf-ad0f-415c-917f-da252abbdafb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b28bb5-cfc0-4b77-8200-9d909bed1a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data details\n",
    "data_details = {\"data_path\": DF_PATH,\n",
    "                \"training_indices\": X_train.index.tolist(),\n",
    "                \"test_indices\":     X_test.index.tolist(), \n",
    "                \"features_names\":   X_train.columns.droplevel(0).tolist(),\n",
    "                \"targets_names\":    Y_train.columns.tolist()}\n",
    "\n",
    "with open(os.path.join(LOG_PATH, LOG_DATA_PKL), \"wb\") as output_file:\n",
    "    pickle.dump(data_details, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c090e737-c67d-467d-a9eb-44e297b946d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = {\"model_description\": \"Random Forest: with PCAs + RBF kernel + Hyperparamter tuning\",\n",
    "         \"model_details\": str(hpt_rf_clf),\n",
    "         \"model_object\": hpt_rf_clf} \n",
    "\n",
    "with open(os.path.join(LOG_PATH, LOG_MODEL_PKL), \"wb\") as output_file:\n",
    "    pickle.dump(model, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1bf695-4b10-4951-82bd-b1358c41587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preformance details\n",
    "classes_metrics = {\"train_scores\": train_scores, \n",
    "                   \"test_scores\":  test_scores}\n",
    "\n",
    "with open(os.path.join(LOG_PATH, LOG_METRICS_PKL), \"wb\") as output_file:\n",
    "    pickle.dump(classes_metrics, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd72bf-5ea5-4a3e-97fc-695335a93152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new run and track \n",
    "with mlflow.start_run(experiment_id=exp.experiment_id, \n",
    "                      run_name=model[\"model_description\"]):\n",
    "    # Log pickles\n",
    "    mlflow.log_artifacts(LOG_PATH)  \n",
    "    \n",
    "    # Track metrics \n",
    "    for metric, score in mean_test_scores.items():\n",
    "        mlflow.log_metric(metric, score) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a428a9f-3310-4971-95f4-d709e4d6ceb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
