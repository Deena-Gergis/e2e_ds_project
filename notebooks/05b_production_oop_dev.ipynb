{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1efdde18-e554-4987-b512-7707701906e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERS_YAML_PATH = \"/home/deena_gergis/iti/iti_e2e_live/data/processed/features_skills_clusters_description.yaml\"\n",
    "\n",
    "TRACKING_URI = \"file:///home/deena_gergis/iti/iti_e2e_live/notebooks/mlruns/\"\n",
    "# EXPERIMENT_NAME = \"stackoverflow_single_model\"\n",
    "\n",
    "LOG_DATA_PKL    =  \"data.pkl\"\n",
    "LOG_MODEL_PKL   =  \"model.pkl\"\n",
    "\n",
    "EXPERIMENT_ID = \"1\"\n",
    "RUN_ID = \"4c35a9c9d26a48e8bfccfae05a63d348\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc851df-a139-4ce4-8a2c-fcbf56db5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sklearn\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa36ab6-5840-42e0-b326-6839fb1fe142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobPrediction:\n",
    "    \"\"\"Production Class for predicting the probability of a job from skills\"\"\"\n",
    "    # Class attributes \n",
    "    path_clusters_config = None\n",
    "    skills_clusters_df   = None\n",
    "    \n",
    "    tracking_uri  = None\n",
    "    experiment_id = None\n",
    "    run_id        = None\n",
    "    \n",
    "    model        = None\n",
    "    all_features = None \n",
    "    all_jobs     = None \n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, tracking_uri, experiment_id, run_id, clusters_yaml_path):\n",
    "        # Store variables\n",
    "        self.tracking_uri    = tracking_uri\n",
    "        self.experiment_id = experiment_id\n",
    "        self.run_id          = run_id\n",
    "        \n",
    "        # Retrieve model and features\n",
    "        mlflow_objs = self.load_mlflow_objs(tracking_uri, \n",
    "                                            experiment_id, \n",
    "                                            run_id)\n",
    "        self.model        = mlflow_objs[0]\n",
    "        self.all_features = mlflow_objs[1]\n",
    "        self.all_jobs     = mlflow_objs[2]\n",
    "        \n",
    "        # Load clusters config \n",
    "        self.path_clusters_config = clusters_yaml_path\n",
    "        self.skills_clusters_df = self.load_clusters_config(clusters_yaml_path)\n",
    "        \n",
    "    # -------------------------------------------\n",
    "    \n",
    "    # Constructor helper functions \n",
    "    \n",
    "    def load_mlflow_objs(self, tracking_uri, experiment_id, run_id):\n",
    "        \"\"\"Load objects from the MLflow run\"\"\"\n",
    "        \n",
    "        # Get artifact path\n",
    "        artifact_path = os.path.join(tracking_uri.replace(\"file://\", \"\"), \n",
    "                                     experiment_id, \n",
    "                                     run_id, \n",
    "                                     'artifacts')\n",
    "        \n",
    "        # Load data pkl\n",
    "        data_path  = os.path.join(artifact_path, LOG_DATA_PKL)\n",
    "        with open(data_path, 'rb') as handle:\n",
    "            data_pkl = pickle.load(handle)\n",
    "            \n",
    "        # Load model pkl\n",
    "        model_path = os.path.join(artifact_path, LOG_MODEL_PKL)\n",
    "        with open(model_path, 'rb') as handle:\n",
    "            model_pkl = pickle.load(handle)\n",
    "\n",
    "        # Return model and data labels \n",
    "        return model_pkl[\"model_object\"], data_pkl[\"features_names\"], data_pkl[\"targets_names\"]\n",
    "    \n",
    "    \n",
    "    def load_clusters_config(self, path_clusters_config):\n",
    "        \"\"\"Load skills clusters developed in 03_feature_engineering.ipynb\"\"\"\n",
    "        \n",
    "        # Read YAML\n",
    "        with open(path_clusters_config, \"r\") as stream:\n",
    "            clusters_config = yaml.safe_load(stream)\n",
    "            \n",
    "        # Format into dataframe\n",
    "        clusters_df = [(cluster_name, cluster_skill)\n",
    "                       for cluster_name, cluster_skills in clusters_config.items()\n",
    "                       for cluster_skill in cluster_skills]\n",
    "        \n",
    "        clusters_df = pd.DataFrame(clusters_df, \n",
    "                                   columns=[\"cluster_name\", \"skill\"])\n",
    "        return clusters_df\n",
    "\n",
    "    \n",
    "    # ========================================================\n",
    "    # **************    Prediction Functions    **************  \n",
    "    # ========================================================\n",
    "    \n",
    "    def create_features_array(self, available_skills):\n",
    "        \"\"\"Create the features array from a list of the available skills\"\"\"\n",
    "        \n",
    "        # Method's helper functions \n",
    "        def create_clusters_features(self, available_skills):\n",
    "            sample_clusters = self.skills_clusters_df.copy()\n",
    "            sample_clusters[\"available_skills\"] = sample_clusters[\"skill\"].isin(available_skills)\n",
    "            cluster_features = sample_clusters.groupby(\"cluster_name\")[\"available_skills\"].sum()\n",
    "            return cluster_features\n",
    "            \n",
    "        def create_skills_features(self, available_skills, exclude_features):\n",
    "            all_features = pd.Series(self.all_features.copy())\n",
    "            skills_names = all_features[~all_features.isin(exclude_features)]\n",
    "            ohe_skills = pd.Series(skills_names.isin(available_skills).astype(int).tolist(), \n",
    "                                   index=skills_names)\n",
    "            return ohe_skills\n",
    "        \n",
    "        # -------------------------\n",
    "        \n",
    "        # Method's main\n",
    "        clusters_features = create_clusters_features(self, available_skills)\n",
    "        skills_features   = create_skills_features(self, available_skills, \n",
    "                                                   exclude_features=clusters_features.index)\n",
    "        # ... Combine features and sort \n",
    "        features = pd.concat([skills_features, clusters_features])\n",
    "        features = features[self.all_features]\n",
    "        return features.values \n",
    "    \n",
    "    \n",
    "    def predict_jobs_probabilities(self, available_skills):\n",
    "        '''Returns probabilities of the different jobs according to the skills'''\n",
    "        # Create features array \n",
    "        features_array = self.create_features_array(available_skills)\n",
    "        \n",
    "        # Predict and format\n",
    "        predictions = self.model.predict_proba([features_array])\n",
    "        predictions = [prob[0][1] for prob in predictions] # Keep positive probs \n",
    "        predictions = pd.Series(predictions, index=self.all_jobs)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    \n",
    "    # ==============================================================\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81308066-8db9-4f9f-95c6-0da929ba7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_pred = JobPrediction(TRACKING_URI, EXPERIMENT_ID, RUN_ID, CLUSTERS_YAML_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c12c9ce-f64a-4bab-83e8-acda62ee30ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       3, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_pred.create_features_array(['Pandas', 'TensorFlow', 'Torch/PyTorch', 'Julia', 'Python'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a76971c-d6fc-4ead-9450-fdd4ca9357d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Academic researcher                              0.543333\n",
       "Data or business analyst                         0.020000\n",
       "Data scientist or machine learning specialist    0.886667\n",
       "Database administrator                           0.000000\n",
       "DevOps specialist                                0.000000\n",
       "Developer, QA or test                            0.020000\n",
       "Developer, back-end                              0.020000\n",
       "Developer, desktop or enterprise applications    0.010000\n",
       "Developer, embedded applications or devices      0.010000\n",
       "Developer, front-end                             0.010000\n",
       "Developer, full-stack                            0.013333\n",
       "Developer, game or graphics                      0.010000\n",
       "Developer, mobile                                0.000000\n",
       "Engineer, data                                   0.030000\n",
       "Scientist                                        0.303333\n",
       "System administrator                             0.010000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_pred.predict_jobs_probabilities(['Pandas', 'TensorFlow', 'Torch/PyTorch', 'Julia', 'Python'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052971be-41c8-4f42-a96f-5359f595128d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
